{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35930,
     "status": "ok",
     "timestamp": 1592898563128,
     "user": {
      "displayName": "ashwin yenigalla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1GDtzkwpsgOtmzgB-2vP1XJk4JIRHvxYY2Ihc=s64",
      "userId": "07956540816182061853"
     },
     "user_tz": -330
    },
    "id": "4G9ep63KzX1C",
    "outputId": "d4704734-a847-4aae-de7c-7f510b60846e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1143,
     "status": "ok",
     "timestamp": 1592895579127,
     "user": {
      "displayName": "ashwin yenigalla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1GDtzkwpsgOtmzgB-2vP1XJk4JIRHvxYY2Ihc=s64",
      "userId": "07956540816182061853"
     },
     "user_tz": -330
    },
    "id": "nobN2ceKzr0q",
    "outputId": "59e46847-91b2-40e5-a901-db494021a88c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/images\n"
     ]
    }
   ],
   "source": [
    "cd /content/gdrive/My Drive/images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3848,
     "status": "ok",
     "timestamp": 1592895594990,
     "user": {
      "displayName": "ashwin yenigalla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1GDtzkwpsgOtmzgB-2vP1XJk4JIRHvxYY2Ihc=s64",
      "userId": "07956540816182061853"
     },
     "user_tz": -330
    },
    "id": "KavMPs6E-cVh",
    "outputId": "821645a1-e2dd-426b-b4fb-f92a874c9310"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detection1.jpg  \u001b[0m\u001b[01;34mTests\u001b[0m/  x2.jpg\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i-WL6Hs98stm"
   },
   "outputs": [],
   "source": [
    "from cv2 import imread, resize\n",
    "import numpy as np\n",
    "#use width and height from your neural network here.\n",
    "\n",
    "def load_for_nn(img_file):\n",
    "    image = imread(img_file)\n",
    "    data = np.array(image)\n",
    "    image = data.flatten()\n",
    "    image = resize(image,(127, 127))\n",
    "    image = image.T\n",
    "\n",
    "    images = np.ones((1,127,127)) #change 1 to any number of images you want to predict, here I just want to predict one\n",
    "    images[0] = image\n",
    "    images = images[:,:,:,np.newaxis]\n",
    "    images /= 255\n",
    "\n",
    "    return images\n",
    "\n",
    "def predict_image(image_path): #insert the path of your image \n",
    "    image = load_for_nn(image_path) #load from the snippet code\n",
    "    raw_word = pipeline.recognize(image) #do the prediction with the neural network\n",
    "    final_word = decode_output(raw_word)[0] #the output of our neural network is only numbers. Use decode_output from image_ocr.py to get the desirable string.\n",
    "    return final_word\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1349,
     "status": "error",
     "timestamp": 1592812655291,
     "user": {
      "displayName": "ashwin yenigalla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1GDtzkwpsgOtmzgB-2vP1XJk4JIRHvxYY2Ihc=s64",
      "userId": "07956540816182061853"
     },
     "user_tz": -330
    },
    "id": "iU5Je525_m9j",
    "outputId": "05e31c84-8ea6-4e7d-e824-c9b8220c92ea"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-bc5b75e134ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/images/x2.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-88e0d7320a7b>\u001b[0m in \u001b[0;36mpredict_image\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#insert the path of your image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_for_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#load from the snippet code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mraw_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecognize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#do the prediction with the neural network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mfinal_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#the output of our neural network is only numbers. Use decode_output from image_ocr.py to get the desirable string.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfinal_word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_ocr/pipeline.py\u001b[0m in \u001b[0;36mrecognize\u001b[0;34m(self, images, detection_kwargs, recognition_kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecognition_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mrecognition_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mbox_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdetection_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         prediction_groups = self.recognizer.recognize_from_boxes(images=images,\n\u001b[1;32m     57\u001b[0m                                                                  \u001b[0mbox_groups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbox_groups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_ocr/detection.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, images, detection_threshold, text_threshold, link_threshold, size_threshold, **kwargs)\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0msize_threshold\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mminimum\u001b[0m \u001b[0marea\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \"\"\"\n\u001b[0;32m--> 679\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompute_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m         boxes = getBoxes(self.model.predict(np.array(images), **kwargs),\n\u001b[1;32m    681\u001b[0m                          \u001b[0mdetection_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetection_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_ocr/detection.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0msize_threshold\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mminimum\u001b[0m \u001b[0marea\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \"\"\"\n\u001b[0;32m--> 679\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompute_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m         boxes = getBoxes(self.model.predict(np.array(images), **kwargs),\n\u001b[1;32m    681\u001b[0m                          \u001b[0mdetection_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetection_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_ocr/detection.py\u001b[0m in \u001b[0;36mcompute_input\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.229\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.225\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mmean\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mvariance\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (254,254) (3,) (254,254) "
     ]
    }
   ],
   "source": [
    "predict_image('/content/gdrive/My Drive/images/x2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5332,
     "status": "error",
     "timestamp": 1592810870654,
     "user": {
      "displayName": "ashwin yenigalla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1GDtzkwpsgOtmzgB-2vP1XJk4JIRHvxYY2Ihc=s64",
      "userId": "07956540816182061853"
     },
     "user_tz": -330
    },
    "id": "pDW94-ecQ9ZS",
    "outputId": "028dc4e0-94cc-487c-ea5b-73ed35bc21c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for /root/.keras-ocr/craft_mlt_25k.h5\n",
      "Looking for /root/.keras-ocr/crnn_kurapan.h5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-aabdb93a5a7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Each list of predictions in prediction_groups is a list of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# (word, box) tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprediction_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecognize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Plot the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_ocr/pipeline.py\u001b[0m in \u001b[0;36mrecognize\u001b[0;34m(self, images, detection_kwargs, recognition_kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecognition_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mrecognition_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mbox_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdetection_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         prediction_groups = self.recognizer.recognize_from_boxes(images=images,\n\u001b[1;32m     57\u001b[0m                                                                  \u001b[0mbox_groups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbox_groups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_ocr/detection.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, images, detection_threshold, text_threshold, link_threshold, size_threshold, **kwargs)\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0msize_threshold\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mminimum\u001b[0m \u001b[0marea\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \"\"\"\n\u001b[0;32m--> 679\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompute_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m         boxes = getBoxes(self.model.predict(np.array(images), **kwargs),\n\u001b[1;32m    681\u001b[0m                          \u001b[0mdetection_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetection_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_ocr/detection.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0msize_threshold\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mminimum\u001b[0m \u001b[0marea\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \"\"\"\n\u001b[0;32m--> 679\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompute_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m         boxes = getBoxes(self.model.predict(np.array(images), **kwargs),\n\u001b[1;32m    681\u001b[0m                          \u001b[0mdetection_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetection_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_ocr/detection.py\u001b[0m in \u001b[0;36mcompute_input\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.229\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.225\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mmean\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mvariance\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1280,6) (3,) (1280,6) "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import keras_ocr\n",
    "\n",
    "# keras-ocr will automatically download pretrained\n",
    "# weights for the detector and recognizer.\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "\n",
    "# Get a set of three example imagesBrotorp0@123\n",
    "images = cv2.imread('/content/gdrive/My Drive/images/x2.jpg')\n",
    "\n",
    "# Each list of predictions in prediction_groups is a list of\n",
    "# (word, box) tuples.\n",
    "prediction_groups = pipeline.recognize(np.array(images))\n",
    "\n",
    "# Plot the predictions\n",
    "#fig, axs = plt.subplots(nrows=len(images), figsize=(20, 20))\n",
    "#for ax, image, predictions in zip(axs, images, prediction_groups):\n",
    "#    keras_ocr.tools.drawAnnotations(image=image, predictions=predictions, ax=ax)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1047,
     "status": "ok",
     "timestamp": 1592810823526,
     "user": {
      "displayName": "ashwin yenigalla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1GDtzkwpsgOtmzgB-2vP1XJk4JIRHvxYY2Ihc=s64",
      "userId": "07956540816182061853"
     },
     "user_tz": -330
    },
    "id": "PQjJrr0-6-Li",
    "outputId": "fd3fc31a-fb19-4c11-b88c-063854337379"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 640, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.shape(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7092,
     "status": "ok",
     "timestamp": 1592810503652,
     "user": {
      "displayName": "ashwin yenigalla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1GDtzkwpsgOtmzgB-2vP1XJk4JIRHvxYY2Ihc=s64",
      "userId": "07956540816182061853"
     },
     "user_tz": -330
    },
    "id": "Qsgm6q6vuibA",
    "outputId": "54c8cce0-b7eb-4c07-d7f4-7cf4fdffb1ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'keras-ocr'...\n",
      "remote: Enumerating objects: 798, done.\u001b[K\n",
      "remote: Total 798 (delta 0), reused 0 (delta 0), pack-reused 798\u001b[K\n",
      "Receiving objects: 100% (798/798), 926.07 KiB | 6.43 MiB/s, done.\n",
      "Resolving deltas: 100% (514/514), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/faustomorales/keras-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20798,
     "status": "ok",
     "timestamp": 1592898319205,
     "user": {
      "displayName": "ashwin yenigalla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1GDtzkwpsgOtmzgB-2vP1XJk4JIRHvxYY2Ihc=s64",
      "userId": "07956540816182061853"
     },
     "user_tz": -330
    },
    "id": "HFnJIah349Cg",
    "outputId": "065c8aeb-f3cc-4ca2-da8b-68910d8dcbdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting craft-text-detector\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/a8/9cc50a7cc62353af8d60263ba84f168127696325a1fa1ec7a90169690e87/craft_text_detector-0.3.1-py3-none-any.whl\n",
      "Collecting gdown>=3.10.1\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/7a/5a892d25b0a105b9d825cdd0c69d2742b83e00f247053f50a7e0a5405439/gdown-3.11.1.tar.gz\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting opencv-python==3.4.8.29\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/0d/6ab6610faa9fff2beedd1ec2cd74867669201302664506f97c3577ff9b0f/opencv_python-3.4.8.29-cp36-cp36m-manylinux1_x86_64.whl (28.3MB)\n",
      "\u001b[K     |████████████████████████████████| 28.3MB 109kB/s \n",
      "\u001b[?25hRequirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from craft-text-detector) (0.6.1+cu101)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from craft-text-detector) (1.5.1+cu101)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.6/dist-packages (from craft-text-detector) (1.4.1)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.6/dist-packages (from gdown>=3.10.1->craft-text-detector) (2.23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from gdown>=3.10.1->craft-text-detector) (3.0.12)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown>=3.10.1->craft-text-detector) (1.12.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown>=3.10.1->craft-text-detector) (4.41.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python==3.4.8.29->craft-text-detector) (1.18.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->craft-text-detector) (7.0.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->craft-text-detector) (0.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown>=3.10.1->craft-text-detector) (2020.4.5.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown>=3.10.1->craft-text-detector) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown>=3.10.1->craft-text-detector) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown>=3.10.1->craft-text-detector) (1.24.3)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]->gdown>=3.10.1->craft-text-detector) (1.7.1)\n",
      "Building wheels for collected packages: gdown\n",
      "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gdown: filename=gdown-3.11.1-cp36-none-any.whl size=9656 sha256=3906dfb4f4727aaa4b61fce06d31028b0ec5befb50d4ad3567a1c0ca1c0832f3\n",
      "  Stored in directory: /root/.cache/pip/wheels/32/8e/8d/0fec7d933759a0880dc34be487e1d92c51ba8fdf4e9f265ff7\n",
      "Successfully built gdown\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: gdown, opencv-python, craft-text-detector\n",
      "  Found existing installation: gdown 3.6.4\n",
      "    Uninstalling gdown-3.6.4:\n",
      "      Successfully uninstalled gdown-3.6.4\n",
      "  Found existing installation: opencv-python 4.1.2.30\n",
      "    Uninstalling opencv-python-4.1.2.30:\n",
      "      Successfully uninstalled opencv-python-4.1.2.30\n",
      "Successfully installed craft-text-detector-0.3.1 gdown-3.11.1 opencv-python-3.4.8.29\n"
     ]
    }
   ],
   "source": [
    "pip install craft-text-detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3777,
     "status": "ok",
     "timestamp": 1592895652410,
     "user": {
      "displayName": "ashwin yenigalla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1GDtzkwpsgOtmzgB-2vP1XJk4JIRHvxYY2Ihc=s64",
      "userId": "07956540816182061853"
     },
     "user_tz": -330
    },
    "id": "aun3aIaT9VCp"
   },
   "outputs": [],
   "source": [
    "from craft_text_detector import Craft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3988,
     "status": "ok",
     "timestamp": 1592895781774,
     "user": {
      "displayName": "ashwin yenigalla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1GDtzkwpsgOtmzgB-2vP1XJk4JIRHvxYY2Ihc=s64",
      "userId": "07956540816182061853"
     },
     "user_tz": -330
    },
    "id": "5r1m66Cq_KGh",
    "outputId": "816c40e8-73b1-41d4-c762-6c5280ddc98d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detection1.jpg  \u001b[0m\u001b[01;34mTests\u001b[0m/  x2.jpg\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1045,
     "status": "ok",
     "timestamp": 1592897685952,
     "user": {
      "displayName": "ashwin yenigalla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1GDtzkwpsgOtmzgB-2vP1XJk4JIRHvxYY2Ihc=s64",
      "userId": "07956540816182061853"
     },
     "user_tz": -330
    },
    "id": "ReFsQ02Y9bRK"
   },
   "outputs": [],
   "source": [
    "image_path = '/content/gdrive/My Drive/images/detection1.jpg'\n",
    "output_dir = '/content/gdrive/My Drive/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3564,
     "status": "ok",
     "timestamp": 1592896253421,
     "user": {
      "displayName": "ashwin yenigalla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1GDtzkwpsgOtmzgB-2vP1XJk4JIRHvxYY2Ihc=s64",
      "userId": "07956540816182061853"
     },
     "user_tz": -330
    },
    "id": "2P-uVrXn_UIz"
   },
   "outputs": [],
   "source": [
    "# create a craft instance\n",
    "craft = Craft(output_dir=output_dir, crop_type=\"poly\", cuda=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29054,
     "status": "ok",
     "timestamp": 1592896287283,
     "user": {
      "displayName": "ashwin yenigalla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1GDtzkwpsgOtmzgB-2vP1XJk4JIRHvxYY2Ihc=s64",
      "userId": "07956540816182061853"
     },
     "user_tz": -330
    },
    "id": "XFwDhd8V_WoQ"
   },
   "outputs": [],
   "source": [
    "prediction_result = craft.detect_text(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1246,
     "status": "ok",
     "timestamp": 1592896296872,
     "user": {
      "displayName": "ashwin yenigalla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1GDtzkwpsgOtmzgB-2vP1XJk4JIRHvxYY2Ihc=s64",
      "userId": "07956540816182061853"
     },
     "user_tz": -330
    },
    "id": "-gTyvAvSABxF"
   },
   "outputs": [],
   "source": [
    "craft.unload_craftnet_model()\n",
    "craft.unload_refinenet_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4544,
     "status": "ok",
     "timestamp": 1592899010829,
     "user": {
      "displayName": "ashwin yenigalla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1GDtzkwpsgOtmzgB-2vP1XJk4JIRHvxYY2Ihc=s64",
      "userId": "07956540816182061853"
     },
     "user_tz": -330
    },
    "id": "uDrC92XSAXIK"
   },
   "outputs": [],
   "source": [
    "#Advanced Usage\n",
    "\n",
    "# import craft functions\n",
    "from craft_text_detector import (\n",
    "    read_image,\n",
    "    load_craftnet_model,\n",
    "    load_refinenet_model,\n",
    "    get_prediction,\n",
    "    export_detected_regions,\n",
    "    export_extra_results,\n",
    "    empty_cuda_cache\n",
    ")\n",
    "\n",
    "# set image path and export folder directory\n",
    "image_path = '/content/gdrive/My Drive/images/x2.jpg'\n",
    "output_dir = '/content/gdrive/My Drive/images/'\n",
    "\n",
    "# read image\n",
    "image = read_image(image_path)\n",
    "\n",
    "# load models\n",
    "refine_net = load_refinenet_model(cuda=True)\n",
    "craft_net = load_craftnet_model(cuda=True)\n",
    "\n",
    "# perform prediction\n",
    "prediction_result = get_prediction(\n",
    "    image=image,\n",
    "    craft_net=craft_net,\n",
    "    refine_net=refine_net,\n",
    "    text_threshold=0.7,\n",
    "    link_threshold=0.4,\n",
    "    low_text=0.4,\n",
    "    cuda=True,\n",
    "    long_size=1280\n",
    ")\n",
    "\n",
    "# export detected text regions\n",
    "exported_file_paths = export_detected_regions(\n",
    "    image_path=image_path,\n",
    "    image=image,\n",
    "    regions=prediction_result[\"boxes\"],\n",
    "    output_dir=output_dir,\n",
    "    rectify=True\n",
    ")\n",
    "\n",
    "# export heatmap, detection points, box visualization\n",
    "export_extra_results(\n",
    "    image_path=image_path,\n",
    "    image=image,\n",
    "    regions=prediction_result[\"boxes\"],\n",
    "    heatmaps=prediction_result[\"heatmaps\"],\n",
    "    output_dir=output_dir\n",
    ")\n",
    "\n",
    "# unload models from gpu\n",
    "empty_cuda_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m2GJUL5kHaxB"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1409,
     "status": "ok",
     "timestamp": 1592898499221,
     "user": {
      "displayName": "ashwin yenigalla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1GDtzkwpsgOtmzgB-2vP1XJk4JIRHvxYY2Ihc=s64",
      "userId": "07956540816182061853"
     },
     "user_tz": -330
    },
    "id": "uslYxsPTGnaC",
    "outputId": "d227845f-e02d-419f-8a40-c59af84d7ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/content/gdrive/My Drive/images/'\n",
      "/root\n"
     ]
    }
   ],
   "source": [
    "cd /content/gdrive/My Drive/images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4275,
     "status": "ok",
     "timestamp": 1592898518389,
     "user": {
      "displayName": "ashwin yenigalla",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh1GDtzkwpsgOtmzgB-2vP1XJk4JIRHvxYY2Ihc=s64",
      "userId": "07956540816182061853"
     },
     "user_tz": -330
    },
    "id": "LlEbTEBqJXz4"
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ryK40VFPJkTB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMFQabAkLAWk+I8E+HFkmGF",
   "name": "Keras_OCR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
